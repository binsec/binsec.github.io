---
layout: post
title:  "KR'23: research paper"
categories: new publication
paper-title: "Active Disjunctive Constraint Acquisition"
topic: "constraint acquisition, machine learning, contract inference"
pdf: "/assets/publications/papers/2023-kr.pdf"
date: 2023-06-13
---

## Motivation

Constraint acquisition (CA) is a method for learning users’ concepts by representing them as a conjunction of constraints. To do so, it takes as input a set of variables and a set of constraints (called the bias) over these variables. From such knowledge, it extracts membership queries (i.e., full assignments of the problem variables), and asks an oracle (usually the user, but it can also be an automated oracle) to classify them. A positive classification means that the assignment is a solution of the target concept, while a negative one means the opposite. CA will thus generate a finite number of membership queries to converge to a unique solution as a conjunction of the constraints from the bias.

While this approach works well for many combinatorial problems over finite domains, some applications require the acquisition of disjunctive constraints, possibly coming from logical implications or negations. Notably, CA has been recently applied to precondition inference, whose goal is to infer on which input a function can be executed without crashing. However, preconditions may contain disjunctions. For example, the precondition of the `sum` function is: `size <= 0 or list != NULL` 

```C
int sum(int* list, int size) {
    int res = 0;

    for (int i = 0; i < size; i++) {
        res += list[i];
    }

    return res;
}
```

What happens if we feed CA with the variables `{list, size}` and the bias `{list != NULL, list = NULL, size <= 0, size > 0}` over this example? In fact, it will not be able to infer the correct precondition and may end up learning `list != NULL`. Indeed, CA cannot infer disjunctions. A workaround could be to add all disjunctions up to some fixed size into the bias. Still, it leads to the bias size explosion, impeding inference.



## DCA: Disjunctive Constraint Acquisition

In this paper, we propose the first CA algorithm tailored to the automatic inference of disjunctive constraints, named DCA. Especially, over the previous example, DCA easily infers the correct precondition `size <= 0 or list != NULL`, automatically generating the following four queries:


<center>
<style type="text/css">
.tg  {border-collapse:collapse;border-color:#93a1a1;border-spacing:0;}
.tg td{background-color:#fdf6e3;border-color:#93a1a1;border-style:solid;border-width:1px;color:#002b36;
  font-family:Arial, sans-serif;font-size:14px;overflow:hidden;padding:6px 15px;word-break:normal;}
.tg th{background-color:#657b83;border-color:#93a1a1;border-style:solid;border-width:1px;color:#fdf6e3;
  font-family:Arial, sans-serif;font-size:14px;font-weight:normal;overflow:hidden;padding:6px 15px;word-break:normal;}
.tg .tg-baqh{text-align:center;vertical-align:top}
.tg .tg-wa1i{font-weight:bold;text-align:center;vertical-align:middle}
.tg .tg-nrix{text-align:center;vertical-align:middle}
</style>
<table class="tg">
<thead>
  <tr>
    <th class="tg-wa1i">list</th>
    <th class="tg-wa1i">size</th>
    <th class="tg-wa1i">classification</th>
  </tr>
</thead>
<tbody>
  <tr>
    <td class="tg-nrix">NULL</td>
    <td class="tg-nrix">1</td>
    <td class="tg-nrix">no</td>
  </tr>
  <tr>
    <td class="tg-nrix">NULL</td>
    <td class="tg-nrix">0</td>
    <td class="tg-nrix">yes</td>
  </tr>
  <tr>
    <td class="tg-nrix">[1, 2]</td>
    <td class="tg-nrix">1</td>
    <td class="tg-nrix">yes</td>
  </tr>
  <tr>
    <td class="tg-baqh">[1, 3]</td>
    <td class="tg-baqh">0</td>
    <td class="tg-baqh">yes</td>
  </tr>
</tbody>
</table>
</center>

**How does it work?** DCA relies on MSS enumeration to infer the target concept. Given an input set of constraints (where the negation of each constraint is also included), it infers the correct concept by asking only membership queries. If a membership query e is classified negatively, DCA excludes from the result the best approximation available for e – computed through MSS enumeration. As usual CA, we prove that DCA always terminates, generates informative queries only, and returns a result that agrees with all tested queries. Moreover, if the target concept can be expressed as a conjunction of disjunctive constraints from the input set of constraints, then DCA infers it.

**Experimental results:** We compared DCA to usual CA over different learning tasks: random, domain, and ultra-metric constraints inference, as well as precondition inference. We show that DCA is able to infer more concepts than basic CA even if we give it the good disjunction size. Especially, DCA is able to infer preconditions with disjunctions of size up to 7 while CA-based approach is limited to disjunctions of size 3.

## Major Contributions

In summary, this paper makes the following major contributions:
* We propose DCA the first inference framework extending CA to infer conjunctions of disjunctive constraints. It elegantly leverages maximal satisfiable subsets (MSS) enumeration to render CA more expressive to efficiently handle disjunctions;
* We prove that DCA enjoys good theoretical properties. Especially, it shares the same guarantees as usual CA, showing that DCA is an appropriate generalization of CA for disjunctive contexts. 
* We evaluate our new learning framework DCA over two different benchmarks, including precondition inference tasks. We show that it highly outperforms CA based approches, being faster and more expressive.

## Further information

* Read the [paper](/assets/publications/papers/2023-kr.pdf)
* To appear at the [International Conference on Principles of Knowledge Representation and Reasoning (KR2023)](https://kr.org/KR2023/) 
